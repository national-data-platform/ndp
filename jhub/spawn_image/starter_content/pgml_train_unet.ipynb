{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe26c5c807465000",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# UNet with Idealized Grass Dataset\n",
    "### [Link to MLFlow Dashboard](http://0.0.0.0:5001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0de7f0-e291-4af3-a351-0b03da6b4d0e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f58f475f4a6331e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from unet.unets import U_net\n",
    "from torch.autograd import Variable\n",
    "# from penalty import DivergenceLoss\n",
    "from unet.utils_unet import train_epoch, eval_epoch, test_epoch\n",
    "from unet.dataset import IdealizedGrasslands\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389e018-343f-4ae8-984a-c4d873086958",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "mlflow.set_experiment(\"UNet\")\n",
    "mlflow.start_run()\n",
    "\n",
    "train_direc=\"./train/\"\n",
    "test_direc=\"./test/\"\n",
    "min_mse=10\n",
    "output_length=100\n",
    "input_length=7\n",
    "learning_rate=0.001\n",
    "dropout_rate=0\n",
    "kernel_size=3\n",
    "batch_size=1\n",
    "max_epochs=1\n",
    "\n",
    "train_indices=list(range(0,3))\n",
    "valid_indices = list(range(3, 5))\n",
    "# test_indices = list(range(600, 650))\n",
    "model=U_net(input_channels = input_length, output_channels = 1, kernel_size = kernel_size,\n",
    "            dropout_rate = dropout_rate).to(device)\n",
    "train_set = IdealizedGrasslands(train_indices, input_length , 15, output_length, train_direc, file='uniform-pgml-success_list_simulation_runs.csv')\n",
    "valid_set =IdealizedGrasslands(valid_indices, input_length , 15, output_length, test_direc, file='uniform-pgml-success_list_simulation_runs.csv')\n",
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 1)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size = batch_size, shuffle = False, num_workers = 1)\n",
    "loss_fun = torch.nn.L1Loss()\n",
    "#regularizer = DivergenceLoss(torch.nn.MSELoss())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, betas = (0.9, 0.999), weight_decay = 4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.9)\n",
    "\n",
    "# Log parameters into MLFlow\n",
    "mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"loss_function\", loss_fun)\n",
    "mlflow.log_param(\"max_epochs\", max_epochs)\n",
    "mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "mlflow.log_param(\"scheduler\", str(scheduler))\n",
    "\n",
    "\n",
    "train_mse = []\n",
    "valid_mse = []\n",
    "test_mse = []\n",
    "for i in range(max_epochs):\n",
    "    mlflow.log_metric(\"Current Training Epoch\", i + 1)\n",
    "    print(f'Epoch {i} started')\n",
    "    start = time.time()\n",
    "    torch.cuda.empty_cache()\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "    teacher_force_ratio=np.maximum(0, 1 - i * 0.03)\n",
    "    train_loss = train_epoch(train_loader, model, optimizer, loss_fun, teacher_force_ratio)\n",
    "    train_mse.append(train_loss)\n",
    "    model.eval()\n",
    "    mse, preds, trues = eval_epoch(valid_loader, model, loss_fun)\n",
    "    valid_mse.append(mse)\n",
    "\n",
    "    # send training metrics to MLFlow\n",
    "    mlflow.log_metric(\"Epoch Loss\", train_loss, step=i)\n",
    "    mlflow.log_metric(\"Epoch Validation\", mse, step=i)\n",
    "    \n",
    "    if valid_mse[-1] < min_mse:\n",
    "        min_mse = valid_mse[-1]\n",
    "        best_model = model\n",
    "        torch.save(best_model, \"unet_model2.pth\")\n",
    "    end = time.time()\n",
    "    if (len(train_mse) > 50 and np.mean(valid_mse[-5:]) >= np.mean(valid_mse[-10:-5])):\n",
    "            break\n",
    "    print(train_mse[-1], valid_mse[-1], round((end-start)/60,5))\n",
    "    print(f'Epoch {i} ended')\n",
    "\n",
    "mlflow.log_artifact(\"unet_model2.pth\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18109c4-38bc-4fff-933e-4014976e6956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
